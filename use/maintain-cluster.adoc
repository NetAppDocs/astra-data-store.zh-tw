---
sidebar: sidebar 
permalink: use/maintain-cluster.html 
keywords: astra, astra data store, kubectl 
summary: 您可以使用搭配Astra Data Store的kubecl命令來維護叢集。 
---
= 管理Astra Data Store叢集
:hardbreaks:
:allow-uri-read: 
:icons: font
:imagesdir: ../media/use/


您可以使用搭配Astra Data Store的kubecl命令來管理叢集。

* <<Add a node>>
* <<Remove a node>>
* <<Place a node in maintenance mode>>
* <<Add drives to a node>>
* <<Replace a drive>>


.您需要的是 #8217 ；需要的是什麼
* 安裝了kubectl和kubecl-astrads外掛程式的系統。請參閱 link:../get-started/install-ads.html["安裝Astra Data Store"]。




== 新增節點

您要新增的節點應該是Kubernetes叢集的一部分、而且其組態應該類似於叢集中的其他節點。


NOTE: 若要使用Astra Control Center新增節點、請參閱 https://docs.netapp.com/us-en/astra-control-center/use/manage-backend.html["將節點新增至儲存後端叢集"^]。

.步驟
. 如果新節點的dataIP尚未納入Astra Data Store叢集CR、請執行下列步驟：
+
.. 編輯叢集CR、並在「adsDataNetworks」*「Addresses」（位址）*欄位中新增額外的dataIP。以適合您環境的適當值取代以大寫字母顯示的資訊：
+
[source, kubectl]
----
kubectl edit astradscluster CLUSTER_NAME -n astrads-system
----
.. 儲存CR。
.. 將節點新增至Astra Data Store叢集。以適合您環境的適當值取代以大寫字母顯示的資訊：
+
[source, kubectl]
----
kubectl astrads nodes add --cluster CLUSTER_NAME
----


. 否則、只要新增節點即可。以適合您環境的適當值取代以大寫字母顯示的資訊：
+
[source, kubectl]
----
kubectl astrads nodes add --cluster CLUSTER_NAME
----
. 確認已新增節點：
+
[source, kubectl]
----
kubectl astrads nodes list
----




== 移除節點

搭配Astra Data Store使用kubectl命令來移除叢集中的節點。

.步驟
. 列出所有節點：
+
[source, kubectl]
----
kubectl astrads nodes list
----
+
回應：

+
[listing]
----
NODE NAME           NODE STATUS    CLUSTER NAME
sti-rx2540-534d...  Added       cluster-multinodes-21209
sti-rx2540-535d...  Added       cluster-multinodes-21209
...
----
. 標記要移除的節點。以適合您環境的適當值取代以大寫字母顯示的資訊：
+
[source, kubectl]
----
kubectl astrads nodes remove NODE_NAME
----
+
回應：

+
[listing]
----
Removal label set on node sti-rx2540-534d.lab.org
Successfully updated ADS cluster cluster-multinodes-21209 desired node count from 4 to 3
----
+
標記要移除的節點後、節點狀態應從「active」（作用中）變更為「present」（目前）。

. 驗證移除節點的「Present（目前）」狀態：
+
[source, kubectl]
----
kubectl get nodes --show-labels
----
+
回應：

+
[listing]
----
NAME                                            STATUS   ROLES                  AGE     VERSION   LABELS
sti-astramaster-050.lab.org   Ready    control-plane,master   3h39m   v1.20.0   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=sti-astramaster-050.lab.org,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=
sti-rx2540-556a.lab.org       Ready    worker                 3h38m   v1.20.0   astrads.netapp.io/cluster=astrads-cluster-890c32c,astrads.netapp.io/storage-cluster-status=active,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=sti-rx2540-556a.lab.org,kubernetes.io/os=linux,node-role.kubernetes.io/worker=true
sti-rx2540-556b.lab.org       Ready    worker                 3h38m   v1.20.0   astrads.netapp.io/cluster=astrads-cluster-890c32c,astrads.netapp.io/storage-cluster-status=active,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=sti-rx2540-556b.lab.org,kubernetes.io/os=linux,node-role.kubernetes.io/worker=true
sti-rx2540-534d.lab.org       Ready    worker                 3h38m   v1.20.0   astrads.netapp.io/storage-cluster-status=present,astrads.netapp.io/storage-node-removal=,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=sti-rx2540-557a.lab.org,kubernetes.io/os=linux,node-role.kubernetes.io/worker=true
sti-rx2540-557b.lab.org       Ready    worker                 3h38m   v1.20.0   astrads.netapp.io/cluster=astrads-cluster-890c32c,astrads.netapp.io/storage-cluster-status=active,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=sti-rx2540-557b.lab.org,kubernetes.io/os=linux,node-role.kubernetes.io/worker=true
----
. 從節點解除安裝Astra Data Store。以適合您環境的適當值取代以大寫字母顯示的資訊：
+
[source, kubectl]
----
kubectl astrads nodes uninstall NODE_NAME
----
. 驗證節點是否已從叢集移除：
+
[source, kubectl]
----
kubectl astrads nodes list
----


節點會從Astra資料儲存區移除。



== 將節點置於維護模式

當您需要執行主機維護或套件升級時、應將節點置於維護模式。


NOTE: 節點必須已是Astra Data Store叢集的一部分。

當節點處於維護模式時、您無法將節點新增至叢集。在此範例中、我們會將節點「nhcitj1525」置於維護模式。

.步驟
. 顯示節點詳細資料：
+
[source, kubectl]
----
kubectl get nodes
----
+
回應：

+
[listing]
----
 NAME             STATUS   ROLES                  AGE     VERSION
 nhcitjj1525      Ready    <none>                 3d18h   v1.23.5
 nhcitjj1526      Ready    <none>                 3d18h   v1.23.5
 nhcitjj1527      Ready    <none>                 3d18h   v1.23.5
 nhcitjj1528      Ready    <none>                 3d18h   v1.23.5
 scs000039783-1   Ready    control-plane,master   3d18h   v1.23.5
----
. 確保節點尚未處於維護模式：
+
[source, kubectl]
----
kubectl astrads maintenance list
----
+
回應（維護模式中沒有節點）：

+
[listing]
----
NAME    NODE NAME  IN MAINTENANCE  MAINTENANCE STATE       MAINTENANCE VARIANT
----
. 啟用維護模式。以適合您環境的適當值取代以大寫字母顯示的資訊：
+
[source, kubectl]
----
kubectl astrads maintenance create CR_NAME --node-name=NODE_NAME --variant=Node
----
+
例如：

+
[source, kubectl]
----
kubectl astrads maintenance create maint1 --node-name="nhcitjj1525" --variant=Node
----
+
回應：

+
[listing]
----
Maintenance mode astrads-system/maint1 created
----
. 列出節點：
+
[source, kubectl]
----
kubectl astrads nodes list
----
+
回應：

+
[listing]
----
NODE NAME       NODE STATUS     CLUSTER NAME
nhcitjj1525     Added           ftap-astra-012
...
----
. 檢查維護模式的狀態：
+
[source, kubectl]
----
kubectl astrads maintenance list
----
+
回應：

+
[listing]
----
NAME    NODE NAME       IN MAINTENANCE  MAINTENANCE STATE       MAINTENANCE VARIANT
node4   nhcitjj1525     true            ReadyForMaintenance     Node
----
+
在「維護中」模式的開頭是「假」、並變更為「真」。「維護狀態」從「準備維護」改為「就緒維護」。

. 節點維護完成後、請停用維護模式：
+
[source, kubectl]
----
kubectl astrads maintenance update maint1 --node-name="nhcitjj1525" --variant=None
----
. 確保節點不再處於維護模式：
+
[source, kubectl]
----
kubectl astrads maintenance list
----




== 新增磁碟機至節點

搭配Astra Data Store使用kubectl命令、將實體或虛擬磁碟機新增至Astra Data Store叢集中的節點。

.您需要的是 #8217 ；需要的是什麼
* 符合下列條件的一或多個磁碟機：
+
** 已安裝在節點（實體磁碟機）或新增至節點VM（虛擬磁碟機）
** 磁碟機上沒有分割區
** 叢集目前未使用磁碟機
** 磁碟機原始容量不超過叢集中的授權原始容量（例如、授權每個CPU核心提供2TB的儲存容量、10個節點的叢集最大原始磁碟機容量為20TB）
** 磁碟機至少為節點中其他作用中磁碟機的大小





NOTE: Astra Data Store每個節點不需要超過16個磁碟機。如果您嘗試新增第17個磁碟機、磁碟機新增要求將遭拒。

.步驟
. 描述叢集：
+
[source, kubectl]
----
kubectl astrads clusters list
----
+
回應：

+
[listing]
----
CLUSTER NAME                    CLUSTER STATUS  NODE COUNT
cluster-multinodes-21209        created         4
----
. 記下叢集名稱。
. 顯示可新增至叢集中所有節點的磁碟機。以叢集名稱取代叢集名稱：
+
[source, kubectl]
----
kubectl astrads adddrive show-available --cluster=CLUSTER_NAME
----
+
回應：

+
[listing]
----
Current cluster drive add status
Licensed cluster capacity: 72.0 TiB
Cluster capacity used: 2.3 TiB
Maximum node size without stranding: 800.0 GiB

Node: node1.name
Current node size: 600.0 GiB
Maximum licensed node size: 18.0 TiB
Total size that can be added to this node without stranding: 200.0 GiB
Add drive minimum/reccomended size: 100.0 GiB. Larger disks will be constrained to this size
NAME IDPATH SERIAL PARTITIONCOUNT SIZE ALREADYINCLUSTER
sdg /dev/disk/by-id/scsi-3c290e16d52479a9af5eac c290e16d52479a9af5eac 0 100 GiB false
sdh /dev/disk/by-id/scsi-3c2935798df68355dee0be c2935798df68355dee0be 0 100 GiB false

Node: node2.name
Current node size: 600.0 GiB
Maximum licensed node size: 18.0 TiB
Total size that can be added to this node without stranding: 200.0 GiB
Add drive minimum/reccomended size: 100.0 GiB. Larger disks will be constrained to this size
No suitable drives to add exist.


Node: node3.name
Current node size: 600.0 GiB
Maximum licensed node size: 18.0 TiB
Total size that can be added to this node without stranding: 200.0 GiB
Add drive minimum/reccomended size: 100.0 GiB. Larger disks will be constrained to this size
NAME IDPATH SERIAL PARTITIONCOUNT SIZE ALREADYINCLUSTER
sdg /dev/disk/by-id/scsi-3c29ee82992ed7a36fc942 c29ee82992ed7a36fc942 0 100 GiB false
sdh /dev/disk/by-id/scsi-3c29312aa362469fb3da9c c29312aa362469fb3da9c 0 100 GiB false

Node: node4.name
Current node size: 600.0 GiB
Maximum licensed node size: 18.0 TiB
Total size that can be added to this node without stranding: 200.0 GiB
Add drive minimum/reccomended size: 100.0 GiB. Larger disks will be constrained to this size
No suitable drives to add exist.
----
. 執行下列其中一項：
+
** 如果所有可用磁碟機的名稱都相同、您可以將其同時新增至各自的節點。以適合您環境的適當值取代以大寫字母顯示的資訊：
+
[source, kubectl]
----
kubectl astrads adddrive create --cluster=CLUSTER_NAME --name REQUEST_NAME --drivesbyname all=DRIVE_NAME
----
** 如果磁碟機的命名方式不同、您可以一次新增一個磁碟機至各自的節點（您需要針對每個需要新增的磁碟機重複此步驟）。以適合您環境的適當值取代以大寫字母顯示的資訊：
+
[source, kubectl]
----
kubectl astrads adddrive create --cluster=CLUSTER_NAME --name REQUEST_NAME --drivesbyname NODE_NAME=DRIVE_NAME
----




Astra Data Store會建立新增磁碟機的要求、並顯示訊息、顯示要求的結果。



== 更換磁碟機

當叢集中的磁碟機故障時、必須儘快更換磁碟機、以確保資料完整性。如果磁碟機故障、您可以在叢集CR節點狀態、叢集健全狀況資訊和度量端點中查看故障磁碟機的相關資訊。您可以使用下列命令範例來查看故障磁碟機資訊。

.顯示nodeStatuses.driveStatuses中故障磁碟機的叢集範例
[source, kubectl]
----
kubectl get adscl -A -o yaml
----
回應：

[listing]
----
...
apiVersion: astrads.netapp.io/v1alpha1
kind: AstraDSCluster
...
nodeStatuses:
  - driveStatuses:
    - driveID: 31205e51-f592-59e3-b6ec-185fd25888fa
      driveName: scsi-36000c290ace209465271ed6b8589b494
      drivesStatus: Failed
    - driveID: 3b515b09-3e95-5d25-a583-bee531ff3f31
      driveName: scsi-36000c290ef2632627cb167a03b431a5f
      drivesStatus: Active
    - driveID: 0807fa06-35ce-5a46-9c25-f1669def8c8e
      driveName: scsi-36000c292c8fc037c9f7e97a49e3e2708
      drivesStatus: Active
...
----
故障磁碟機CR會在叢集中自動建立、名稱對應於故障磁碟機的UUID。

[source, kubectl]
----
kubectl get adsfd -A -o yaml
----
回應：

[listing]
----
...
apiVersion: astrads.netapp.io/v1alpha1
kind: AstraDSFailedDrive
metadata:
    name: c290a-5000-4652c-9b494
    namespace: astrads-system
spec:
  executeReplace: false
  replaceWith: ""
 status:
   cluster: arda-6e4b4af
   failedDriveInfo:
     failureReason: AdminFailed
     inUse: false
     name: scsi-36000c290ace209465271ed6b8589b494
     path: /dev/disk/by-id/scsi-36000c290ace209465271ed6b8589b494
     present: true
     serial: 6000c290ace209465271ed6b8589b494
     node: sti-rx2540-300b.lab.org
   state: ReadyToReplace
----
[source, kubectl]
----
kubectl astrads faileddrive list --cluster arda-6e4b4af
----
回應：

[listing]
----
NAME       NODE                             CLUSTER        STATE                AGE
6000c290   sti-rx2540-300b.lab.netapp.com   ard-6e4b4af    ReadyToReplace       13m
----
.步驟
. 使用「kubectl astrads filleddrive show-replacees」命令列出可能的更換磁碟機、該命令可篩選符合更換限制的磁碟機（未在叢集中使用、未掛載、無分割區、等於或大於故障磁碟機）。
+
若要列出所有磁碟機而不篩選可能的更換磁碟機、請在「show -replacement」命令中新增「-all」。

+
[source, kubectl]
----
kubectl astrads faileddrive show-replacements --cluster ard-6e4b4af --name 6000c290
----
+
回應：

+
[listing]
----
NAME  IDPATH             SERIAL  PARTITIONCOUNT   MOUNTED   SIZE
sdh   /scsi-36000c29417  45000c  0                false     100GB
----
. 使用「放置」命令、以通過的序號取代磁碟機。命令會完成替換、如果經過「-wait」時間、則會失敗。
+
[source, kubectl]
----
kubectl astrads faileddrive replace --cluster arda-6e4b4af --name 6000c290 --replaceWith 45000c --wait
----
+
回應：

+
[listing]
----
Drive replacement completed successfully
----
+

NOTE: 如果使用不適當的「-replaceWith」序號來執行「kubectl astrads故障磁碟機更換」、則會出現類似以下的錯誤：

+
[source, kubectl]
----
kubectl astrads replacedrive replace --cluster astrads-cluster-f51b10a --name 6000c2927 --replaceWith BAD_SERIAL_NUMBER
Drive 6000c2927 replacement started
Failed drive 6000c2927 has been set to use BAD_SERIAL_NUMBER as a replacement
...
Drive replacement didn't complete within 25 seconds
Current status: {FailedDriveInfo:{InUse:false Present:true Name:scsi-36000c2 FiretapUUID:444a5468 Serial:6000c Path:/scsi-36000c FailureReason:AdminFailed Node:sti-b200-0214a.lab.netapp.com} Cluster:astrads-cluster-f51b10a State:ReadyToReplace Conditions:[{Message: "Replacement drive serial specified doesn't exist", Reason: "DriveSelectionFailed", Status: False, Type:' Done"]}
----
. 若要重新執行磁碟機更換、請使用之前的命令「-force」：
+
[source, kubectl]
----
kubectl astrads faileddrive replace --cluster astrads-cluster-f51b10a --name 6000c2927 --replaceWith VALID_SERIAL_NUMBER --force
----




== 以取得更多資訊

* link:../use/kubectl-commands-ads.html["使用kvecll命令管理Astra Data Store資源"]
* https://docs.netapp.com/us-en/astra-control-center/use/manage-backend.html#add-nodes-to-a-storage-backend-cluster["將節點新增至Astra Control Center的儲存後端叢集"^]

